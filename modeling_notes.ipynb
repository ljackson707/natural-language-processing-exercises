{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Modeling\n",
    "\n",
    "The \"big idea\" of modeling is to determine what a document is all about; which words are important or not. The main task is to determine the weight of each word, relative to the document.\n",
    "\n",
    "\n",
    "## What\n",
    "- Introducing our _Dramatis Personae_, the characters in our play:\n",
    "    - `Term frequency` is a direct way to measure what a document is about, but it over-emphasizes common terms. Consider term frequency the baseline, kinda like how median, median, or mode can be baselines. It's at least somewhere to start, even if it's a blunt tool w/ some issues.\n",
    "    - `TF` = # times a word occurs divided by the total amount of words. \n",
    "    - `Bag of words` is a representation of a document as a vector, where the values indicate word frequency.\n",
    "        ```\n",
    "        string = \"Mary had a little lamb, little lamb, little lamb.\"\n",
    "        string = string.replace(\",\", \"\")\n",
    "        words = string.split()\n",
    "        bag_of_words = pd.Series(words).value_counts()\n",
    "        ```\n",
    "    - Word clouds are a visual bag of words with larger font sizes representing higher term frequency\n",
    "    - Inverse Document Frequency, `IDF`, tells us how much information a word provides. \n",
    "        - A higher IDF means that a word provides more information. That is, it is more relevant within a single document.\n",
    "        - As the number of documents that a word appears in increases, the IDF value decreases.\n",
    "        - Example: if \"Codeup\" appears frequently in every document in a list of documents, then the word doesn't add much new information on any given individual document.\n",
    "        - Example: if \"scholarship\" shows up a whole bunch one one or two documents, but not frequently across the corups of documents, then we can conclude that that word conveys more meaning.\n",
    "        \n",
    "    - `TF-IDF` is the product of `tf * idf` and is \n",
    "\n",
    "\n",
    "## So What?\n",
    "- Determining what a document is about is both valuable and challening.\n",
    "- Term frequency is super sensitive to noise\n",
    "- TF-IDF is super common and has been used in the majority of text based recommendation systems. See [tf-idf in Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "## Now What?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>Difficult? Simply solve the mystery of Farpoi...</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>As simple as that.</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>Farpoint Station. Even the name sounds myster...</td>\n",
       "      <td>TROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>It's hardly simple, Data, to negotiate a frie...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>Inquiry. The word snoop?</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51983</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>Of course. Have a seat.</td>\n",
       "      <td>RIKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51984</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>Would you care to deal, sir?</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51985</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>Oh, er, thank you, Mister Data. Actually, I u...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51986</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>You were always welcome.</td>\n",
       "      <td>TROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51987</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>So. Five card stud, nothing wild, and the sky...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38931 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                episode_name  \\\n",
       "0      Encounter at Farpoint   \n",
       "1      Encounter at Farpoint   \n",
       "2      Encounter at Farpoint   \n",
       "3      Encounter at Farpoint   \n",
       "4      Encounter at Farpoint   \n",
       "...                      ...   \n",
       "51983        All Good Things   \n",
       "51984        All Good Things   \n",
       "51985        All Good Things   \n",
       "51986        All Good Things   \n",
       "51987        All Good Things   \n",
       "\n",
       "                                                    line character  \n",
       "0       Difficult? Simply solve the mystery of Farpoi...      DATA  \n",
       "1                                     As simple as that.    PICARD  \n",
       "2       Farpoint Station. Even the name sounds myster...      TROI  \n",
       "3       It's hardly simple, Data, to negotiate a frie...    PICARD  \n",
       "4                               Inquiry. The word snoop?      DATA  \n",
       "...                                                  ...       ...  \n",
       "51983                            Of course. Have a seat.     RIKER  \n",
       "51984                       Would you care to deal, sir?      DATA  \n",
       "51985   Oh, er, thank you, Mister Data. Actually, I u...    PICARD  \n",
       "51986                           You were always welcome.      TROI  \n",
       "51987   So. Five card stud, nothing wild, and the sky...    PICARD  \n",
       "\n",
       "[38931 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tng.csv\")\n",
    "\n",
    "top_15_characters = df.character.value_counts().index[0:15]\n",
    "\n",
    "top_15 = df[df.character.isin(top_15_characters)]\n",
    "top_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51988, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = ['r', 'u', '2', 'ltgt']\n",
    "\n",
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return \" \".join([wnl.lemmatize(word) for word in words if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>difficult simply solve mystery farpoint station</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>simple</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>farpoint station even name sound mysterious</td>\n",
       "      <td>TROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>hardly simple data negotiate friendly agreemen...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>inquiry word snoop</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            episode_name                                               line  \\\n",
       "0  Encounter at Farpoint    difficult simply solve mystery farpoint station   \n",
       "1  Encounter at Farpoint                                             simple   \n",
       "2  Encounter at Farpoint        farpoint station even name sound mysterious   \n",
       "3  Encounter at Farpoint  hardly simple data negotiate friendly agreemen...   \n",
       "4  Encounter at Farpoint                                 inquiry word snoop   \n",
       "\n",
       "  character  \n",
       "0      DATA  \n",
       "1    PICARD  \n",
       "2      TROI  \n",
       "3    PICARD  \n",
       "4      DATA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.line = df.line.apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this split function later to create in-sample and out-of-sample datasets for modeling\n",
    "def split(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    3 way split for train, validate, and test datasets\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "    \n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train[stratify_by])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split(top_15, 'character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X variables\n",
    "X_train = train.line\n",
    "X_validate = validate.line\n",
    "X_test = test.line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our y variables\n",
    "y_train = train.character\n",
    "y_validate = validate.character\n",
    "y_test = test.character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tfidf vectorizer object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "# Use the object\n",
    "X_train_vectorized = tfidf.transform(X_train)\n",
    "X_validate_vectorized = tfidf.transform(X_validate)\n",
    "X_test_vectorized = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Now you have a vactorized dataset and its fit on the clasification model.\n",
    "lm = LogisticRegression().fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5438073394495413"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "(train.actual == train.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3987585616438356"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(validate.actual == validate.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little less due to overfiting, need to create a feature for each episode to get the gap closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x13346 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have a trained model, lets use our model to predict the charecter of any given line.\n",
    "lines = pd.Series([\n",
    "    \"we have a responsibility\", \n",
    "    \"set phasers to stun\", \n",
    "    \"the warp drive is about to go critical\", \n",
    "    \"What does it mean to be human? I cannot calculate feelings\", \n",
    "    \"Romulan bird of prey decloaking off the port bow\"\n",
    "])\n",
    "\n",
    "# apply clean \n",
    "lines = lines.apply(clean)\n",
    "\n",
    "# We have to vectorize these inputs if we'regoing to be able to use the classification model.\n",
    "lines = tfidf.transform(lines)\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RIKER', 'RIKER', 'LAFORGE', 'DATA', 'WORF'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wesley = train[train.actual == \"Wesley\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy \n",
    "(wesley.actual == wesley.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    COMPUTER       0.97      0.24      0.38       272\n",
      "     CRUSHER       0.72      0.28      0.41      1521\n",
      "        DATA       0.62      0.72      0.66      3008\n",
      "      GUINAN       0.00      0.00      0.00       234\n",
      "     LAFORGE       0.63      0.48      0.55      2048\n",
      "     LWAXANA       1.00      0.00      0.01       201\n",
      "      PICARD       0.49      0.88      0.63      5984\n",
      "     PULASKI       1.00      0.00      0.01       256\n",
      "           Q       1.00      0.01      0.01       274\n",
      "       RIKER       0.51      0.48      0.50      3421\n",
      "          RO       0.75      0.02      0.03       194\n",
      "       TASHA       1.00      0.01      0.02       247\n",
      "        TROI       0.56      0.27      0.36      1612\n",
      "      WESLEY       0.73      0.06      0.11       693\n",
      "        WORF       0.61      0.42      0.50      1835\n",
      "\n",
      "    accuracy                           0.54     21800\n",
      "   macro avg       0.71      0.26      0.28     21800\n",
      "weighted avg       0.59      0.54      0.50     21800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = train.actual.value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting PICARD has 0.88\n",
      "Predicting RIKER has 0.48\n",
      "Predicting DATA has 0.72\n",
      "Predicting LAFORGE has 0.48\n",
      "Predicting WORF has 0.42\n",
      "Predicting TROI has 0.27\n",
      "Predicting CRUSHER has 0.28\n",
      "Predicting WESLEY has 0.06\n",
      "Predicting Q has 0.01\n",
      "Predicting COMPUTER has 0.24\n",
      "Predicting PULASKI has 0.0\n",
      "Predicting TASHA has 0.01\n",
      "Predicting GUINAN has 0.0\n",
      "Predicting LWAXANA has 0.0\n",
      "Predicting RO has 0.02\n"
     ]
    }
   ],
   "source": [
    "for character in characters:\n",
    "    character_lines = train[train.actual == character]\n",
    "    accuracy = (character_lines.actual == character_lines.predicted).mean()\n",
    "    print(f'Predicting {character} has {round(accuracy, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
